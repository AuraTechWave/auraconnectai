# backend/modules/pos_migration/schemas/migration_schemas.py

"""
Pydantic schemas for POS migration operations.
Defines the data structures used throughout the migration process.
"""

from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional, Literal
from datetime import datetime
from decimal import Decimal
from enum import Enum


class MigrationComplexity(str, Enum):
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"


class FieldTransformationType(str, Enum):
    NONE = "none"
    LOWERCASE = "lowercase"
    UPPERCASE = "uppercase"
    PARSE_JSON = "parse_json"
    PARSE_DECIMAL = "parse_decimal"
    CUSTOM = "custom"


class AnomalyType(str, Enum):
    HIGH_PRICE = "high_price"
    LOW_PRICE = "low_price"
    MISSING_PRICE = "missing"
    DECIMAL_ERROR = "decimal_error"
    DUPLICATE = "duplicate"
    INVALID_FORMAT = "invalid_format"


class AnommalySeverity(str, Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class ConsentStatus(str, Enum):
    PENDING = "pending"
    GRANTED = "granted"
    DENIED = "denied"
    EXPIRED = "expired"


# Field Mapping Schemas
class FieldMapping(BaseModel):
    """Represents a mapping between source and target fields"""
    source_field: str
    target_field: str
    confidence: float = Field(ge=0.0, le=1.0)
    transformation: FieldTransformationType = FieldTransformationType.NONE
    notes: Optional[str] = None
    custom_logic: Optional[str] = None
    
    @validator('confidence')
    def validate_confidence(cls, v):
        return round(v, 2)


class MappingSuggestion(BaseModel):
    """AI-generated field mapping suggestion"""
    source: str
    target: str
    confidence: float = Field(ge=0.0, le=1.0)
    reasoning: str
    alternative_targets: Optional[List[str]] = []


# Migration Plan Schemas
class MigrationPlan(BaseModel):
    """Comprehensive migration plan generated by AI analysis"""
    field_mappings: List[FieldMapping]
    data_quality_issues: List[str]
    complexity: MigrationComplexity
    estimated_hours: float
    risk_factors: List[str]
    recommendations: List[str]
    confidence_score: float = Field(ge=0.0, le=1.0)
    generated_at: datetime = Field(default_factory=datetime.utcnow)


# Validation Schemas
class ValidationAnomaly(BaseModel):
    """Represents a data validation anomaly"""
    type: AnomalyType
    severity: AnommalySeverity
    affected_items: List[str]
    description: str
    suggested_action: str
    sample_data: Optional[Dict[str, Any]] = None


class ValidationSummary(BaseModel):
    """Summary of validation results"""
    total_issues: int
    requires_manual_review: bool
    confidence: float = Field(ge=0.0, le=1.0)
    critical_issues: int = 0
    warnings: int = 0


class ValidationReport(BaseModel):
    """Complete validation report for migration data"""
    anomalies: List[ValidationAnomaly]
    summary: ValidationSummary
    validated_at: datetime = Field(default_factory=datetime.utcnow)
    validator_version: str = "1.0.0"


# Token Usage Schemas
class TokenUsage(BaseModel):
    """Track AI token usage for billing"""
    migration_id: str
    tenant_id: str
    operation_type: str
    model: str
    input_tokens: int
    output_tokens: int
    total_tokens: int = 0
    cost_usd: Decimal = Field(decimal_places=6)
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    
    @validator('total_tokens', always=True)
    def calculate_total(cls, v, values):
        return values.get('input_tokens', 0) + values.get('output_tokens', 0)


class TokenCostReport(BaseModel):
    """Cost report for token usage"""
    tenant_id: str
    period: str
    total_cost: Decimal = Field(decimal_places=2)
    by_operation: Dict[str, Decimal]
    by_model: Dict[str, Decimal]
    token_count: Dict[str, int]
    optimization_suggestions: List[str]
    generated_at: datetime = Field(default_factory=datetime.utcnow)


# Migration Status Schemas
class MigrationPhase(str, Enum):
    SETUP = "setup"
    ANALYSIS = "analysis"
    MAPPING = "mapping"
    VALIDATION = "validation"
    IMPORT = "import"
    VERIFICATION = "verification"
    COMPLETION = "completion"


class MigrationStatus(BaseModel):
    """Current status of a migration"""
    migration_id: str
    phase: MigrationPhase
    progress_percent: float = Field(ge=0.0, le=100.0)
    items_processed: int = 0
    total_items: int = 0
    errors: List[Dict[str, Any]] = []
    warnings: List[Dict[str, Any]] = []
    started_at: datetime
    estimated_completion: Optional[datetime] = None
    current_operation: Optional[str] = None


# Customer Communication Schemas
class ConsentRequest(BaseModel):
    """Customer consent request for data migration"""
    customer_id: str
    customer_email: str
    data_categories: List[str]
    purpose: str
    retention_days: int
    consent_token: str
    expires_at: datetime
    legal_basis: str = "legitimate_interest"


class ConsentResponse(BaseModel):
    """Customer's response to consent request"""
    consent_token: str
    status: ConsentStatus
    granted_categories: List[str] = []
    denied_categories: List[str] = []
    responded_at: datetime = Field(default_factory=datetime.utcnow)
    ip_address: Optional[str] = None


class MigrationSummaryData(BaseModel):
    """Data for generating migration summary"""
    customer_name: str
    restaurant_name: str
    items_count: int
    categories_count: int
    modifiers_count: int
    orders_count: int = 0
    loyalty_points_migrated: Optional[int] = None
    migration_duration_hours: float
    new_features_available: List[str]


# Audit Trail Schemas
class AuditLogEntry(BaseModel):
    """Single audit log entry"""
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    migration_id: str
    operation: str
    user_id: Optional[str] = None
    agent_name: Optional[str] = None
    details: Dict[str, Any]
    data_categories: List[str] = []
    compliance_notes: Optional[str] = None


class ComplianceReport(BaseModel):
    """Compliance report for migration"""
    migration_id: str
    gdpr_compliant: bool
    ccpa_compliant: bool
    consent_records: List[ConsentResponse]
    data_inventory: Dict[str, List[str]]
    retention_schedule: Dict[str, int]
    deletion_requests: List[Dict[str, Any]]
    generated_at: datetime = Field(default_factory=datetime.utcnow)
    auditor_version: str = "1.0.0"


# Migration Configuration Schemas
class MigrationOptions(BaseModel):
    """Configuration options for migration"""
    import_historical_data: bool = True
    historical_days: int = 365
    import_customer_data: bool = True
    require_consent: bool = True
    validate_pricing: bool = True
    use_ai_assistance: bool = True
    ai_confidence_threshold: float = Field(default=0.7, ge=0.0, le=1.0)
    batch_size: int = Field(default=100, ge=1, le=1000)
    parallel_workers: int = Field(default=4, ge=1, le=16)


class POSConnectionConfig(BaseModel):
    """Configuration for connecting to POS system"""
    pos_type: Literal["toast", "clover", "square"]
    credentials: Dict[str, Any]
    test_mode: bool = False
    api_version: Optional[str] = None
    custom_headers: Dict[str, str] = {}


# WebSocket Event Schemas
class MigrationProgressEvent(BaseModel):
    """Real-time migration progress update"""
    type: Literal["progress", "phase_change", "error", "warning", "completion"]
    migration_id: str
    data: Dict[str, Any]
    timestamp: datetime = Field(default_factory=datetime.utcnow)


class MigrationErrorEvent(BaseModel):
    """Migration error event"""
    migration_id: str
    error_code: str
    error_message: str
    affected_items: List[str] = []
    recoverable: bool = True
    suggested_action: Optional[str] = None
    timestamp: datetime = Field(default_factory=datetime.utcnow)